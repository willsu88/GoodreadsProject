{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep Params for MatrixFactorization\n",
    "\n",
    "This notebook is used to sweep the K parameters in our Matrix Factorization model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: a 20000 by 426 rating matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: a json file that contains keys (K, reg) mapped to training MSE and test MSE's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The json file \"matrix_factorization_all_params.json\" contains all the training and test MSE's that we swept.\n",
    "The params we swept range from:\n",
    "1. k = 50 - 130\n",
    "2. reg = 1 - 10\n",
    "3. niter = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import scipy.linalg as la\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../ShrinkMatrices/\"\n",
    "npz_filename = path + \"rating_matrix_shrunk.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparse_rating_matrix = sp.load_npz(npz_filename)\n",
    "sparse_rating_matrix = sparse_rating_matrix.astype(\"int8\")\n",
    "dense_rating_matrix = sparse_rating_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14473)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_rating_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44554"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(dense_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030784218890347543"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(dense_rating_matrix) / (dense_rating_matrix.shape[0] * dense_rating_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method: randomly select 10% of user-book pairs that have nonzero entry as test setthe set is train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tr now is 1d array version of dense_rating_matrix\n",
    "X_tr = np.asarray(dense_rating_matrix.copy())\n",
    "X_tr = X_tr.flatten()\n",
    "\n",
    "nonzero_pairs = np.nonzero(X_tr)[0]\n",
    "num_non_zero_pairs = len(nonzero_pairs)\n",
    "\n",
    "total_num_pairs = X_tr.shape[0]\n",
    "num_testing_pairs = int(0.1 * num_non_zero_pairs)\n",
    "\n",
    "# seeds the random generator\n",
    "np.random.seed(0)\n",
    "\n",
    "# indices of 1d array X_tr\n",
    "testing_pair_indices = np.random.choice(nonzero_pairs, num_testing_pairs, replace=False)\n",
    "training_pair_indices = list(set(np.arange(total_num_pairs)) - set(testing_pair_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8503229"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_pair_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = X_tr.copy()\n",
    "\n",
    "# sets testing pairs in training set to be 0\n",
    "X_tr[testing_pair_indices] = 0\n",
    "\n",
    "# sets training pairs in testing set to be 0\n",
    "X_te[training_pair_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150939"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16771"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes X_tr and X_te back to shape of dense_rating_matrix\n",
    "\n",
    "X_tr = X_tr.reshape((dense_rating_matrix.shape[0], dense_rating_matrix.shape[1]))\n",
    "X_te = X_te.reshape((dense_rating_matrix.shape[0], dense_rating_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150939"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16771"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = None\n",
    "dense_rating_matrix = None\n",
    "sparse_rating_matrix = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error and Train Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Our error function is a simple MSE function.\n",
    "2. Our train function uses alternating least squares to find the most optimal UV to decompose our rating matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X, nnz_indices, U, V, reg, verbose=False):\n",
    "    \"\"\" Compute the mean error of the observed ratings in X and their estimated values. \n",
    "        Args: \n",
    "            X (numpy 2D array) : a ratings matrix as specified above \n",
    "            nnz_indices (numpy 2D array) : nonzero indices of dense_rating_matrix\n",
    "            U (numpy 2D array) : a matrix of features for each user (m x k)\n",
    "            V (numpy 2D array) : a matrix of features for each movie (k x n)\n",
    "            reg (float): regularization parameter\n",
    "        Returns: \n",
    "            (float) : the mean squared error of the observed ratings with their estimated values with penalty for u and v coefficients\n",
    "        \"\"\"\n",
    "\n",
    "    num_nnz = np.sum(nnz_indices)\n",
    "    term_1 = np.sum(np.multiply(nnz_indices, ((np.matmul(U, V) - X) ** 2)))\n",
    "    term_2 = reg * np.sum(U * U)\n",
    "    term_3 = reg * np.sum(V * V)\n",
    "\n",
    "    return (term_1 + term_2 + term_3) / num_nnz\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "def train(X_tr, X_te, U_init, V_init, k, niters=10, reg=1, verbose=False):\n",
    "    \"\"\" Train a collaborative filtering model. \n",
    "        Args: \n",
    "            X_tr (numpy 2D array) : the training ratings matrix as specified above\n",
    "            X_te (numpy 2D array) : the testing ratings matrix as specified above\n",
    "            U_init (numpy 2D array) : an initial matrix of features for each user\n",
    "            V_init (numpy 2D array) : an initial matrix of features for each movie\n",
    "            k (int) : the number of features used in the CF model\n",
    "            niters (int) : number of iterations to run\n",
    "            reg (float) : regularization parameter\n",
    "            verbose (boolean) : verbosity flag for printing useful messages\n",
    "            \n",
    "        Returns:\n",
    "            (U,V) : A pair of the resulting learned matrix factorization\n",
    "    \"\"\"\n",
    "    \n",
    "    U = np.empty((X_tr.shape[0], k))\n",
    "    V = np.empty((k, X_tr.shape[1]))\n",
    "\n",
    "    num_users, num_items = X_tr.shape\n",
    "    reg_matrix = reg * np.eye(k,k)\n",
    "    \n",
    "    nnz_indices = (X_tr != 0)\n",
    "    nnz_indices_te = (X_te != 0)\n",
    "    \n",
    "    for iteration in range(1, niters + 1):\n",
    "        \n",
    "        # fix V and update U\n",
    "        for i in range(num_users):\n",
    "            idx = nnz_indices[i,:]\n",
    "            lhs = V[:,idx]\n",
    "            rhs = np.matmul(lhs, X_tr[i, idx].T)\n",
    "            lhs = np.matmul(lhs, lhs.T) + reg_matrix\n",
    "            U[i,:] = np.linalg.solve(lhs, rhs).T\n",
    "\n",
    "        # fix U and update V\n",
    "        for j in range(num_items):\n",
    "            idx = nnz_indices[:,j]\n",
    "            lhs = U[idx,:]\n",
    "            rhs = np.matmul(lhs.T, X_tr[idx, j])\n",
    "            lhs = np.matmul(lhs.T, lhs) + reg_matrix\n",
    "            V[:,j] = np.linalg.solve(lhs, rhs)\n",
    "        \n",
    "        # save some memory\n",
    "        idx = None\n",
    "        lhs = None\n",
    "        rhs = None\n",
    "        gc.collect()\n",
    "        \n",
    "        print (\"--------------------------------------------------\")\n",
    "        print (\"Iteration: \" + str(iteration))\n",
    "        \n",
    "        \n",
    "        training_error = error(X_tr, nnz_indices, U, V, 0, verbose)\n",
    "        testing_error = error(X_te, nnz_indices_te, U, V, 0, verbose)\n",
    "        if verbose:\n",
    "            train_list.append(training_error)\n",
    "            test_list.append(testing_error)\n",
    "            print (\"Training error: \" + str(training_error))\n",
    "            print (\"Testing error: \" + str(testing_error))\n",
    "        \n",
    "        print (\"--------------------------------------------------\")\n",
    "            \n",
    "    return (training_error, testing_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model using the K specified "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where you can change your params to speicify the params that you want to sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = np.concatenate([np.arange(20, 41), np.arange(81, 101)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have prepared 30 notebooks to sweep parameters in parrallel, here is a simple calculation that we employed to see which notebook to sweep which parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 21, 22])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if_write_file = True\n",
    "\n",
    "notebook_num = 3\n",
    "total_notebook_num = 15\n",
    "\n",
    "k_per_notebook = int(len(k_range) / 15) + 1\n",
    "\n",
    "k_range = k_range[(k_per_notebook * (notebook_num - 1)):(k_per_notebook * notebook_num)]\n",
    "\n",
    "k_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the model starts training and sweeping through the params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1) (0.10157804962606012, 3.2723173993536854)\n",
      "k = 20 saved\n",
      "\n",
      "(21, 1) (0.2756627581117208, 2.3634534367614677)\n",
      "k = 21 saved\n",
      "\n",
      "(22, 1) (0.2652228751573767, 2.3544869122944485)\n",
      "k = 22 saved\n",
      "\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "parameter_dict = {}\n",
    "niters = 20\n",
    "reg_range = np.arange(1, 26)\n",
    "\n",
    "for k in k_range:\n",
    "\n",
    "    # initialize U and V\n",
    "    # these will not be modified\n",
    "    U_init = np.apply_along_axis(lambda x: x/sum(x), 1, abs(np.random.randn(X_tr.shape[0],k)))\n",
    "    V_init = np.apply_along_axis(lambda x: x/sum(x), 1, abs(np.random.randn(k,X_tr.shape[1])))\n",
    "            \n",
    "    for reg in reg_range:\n",
    "        parameter_dict[str((k, reg))] = train(X_tr, X_te, U_init, V_init, k, niters, reg, verbose=False)\n",
    "        print (str((k, reg)) + \" \" + str(parameter_dict[str((k, reg))]))\n",
    "    \n",
    "    # write to file for every k\n",
    "    \n",
    "    if if_write_file:\n",
    "        with open(str(notebook_num) + \".json\", \"w+\") as f:\n",
    "            json.dump(parameter_dict, f)\n",
    "            print (\"k = \" + str(k) + \" saved\")\n",
    "            print (\"\")\n",
    "    \n",
    "print (\"Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model with Best Params\n",
    "Our best params are\n",
    "1. k = 80\n",
    "2. reg = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration: 1\n",
      "Training error: 0.14786547414005335\n",
      "Testing error: 1.508293806924531\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 2\n",
      "Training error: 0.08154031858926152\n",
      "Testing error: 1.3588202682288506\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 3\n",
      "Training error: 0.06524791997434765\n",
      "Testing error: 1.2924817885412647\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 4\n",
      "Training error: 0.058639412653340994\n",
      "Testing error: 1.2476283969129145\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 5\n",
      "Training error: 0.055477872743219\n",
      "Testing error: 1.2182995997716797\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 6\n",
      "Training error: 0.05374380665646557\n",
      "Testing error: 1.199097648596468\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 7\n",
      "Training error: 0.052695081777782565\n",
      "Testing error: 1.1864327098142682\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 8\n",
      "Training error: 0.05201307840133525\n",
      "Testing error: 1.1779697778983187\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 9\n",
      "Training error: 0.05154435913731266\n",
      "Testing error: 1.1722272984649027\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 10\n",
      "Training error: 0.05120828078422558\n",
      "Testing error: 1.1682710728818455\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 11\n",
      "Training error: 0.05095933359984667\n",
      "Testing error: 1.165506058210359\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 12\n",
      "Training error: 0.05077024304121683\n",
      "Testing error: 1.1635467796007035\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 13\n",
      "Training error: 0.050623799970050586\n",
      "Testing error: 1.1621391793575868\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 14\n",
      "Training error: 0.05050865715698282\n",
      "Testing error: 1.1611132808797697\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 15\n",
      "Training error: 0.050417046182217234\n",
      "Testing error: 1.1603539423976685\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 16\n",
      "Training error: 0.05034347641145236\n",
      "Testing error: 1.1597823657758797\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 17\n",
      "Training error: 0.050283961096965424\n",
      "Testing error: 1.1593441587591524\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 18\n",
      "Training error: 0.05023553892488419\n",
      "Testing error: 1.159001494065538\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 19\n",
      "Training error: 0.05019596774489035\n",
      "Testing error: 1.1587278874739313\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 20\n",
      "Training error: 0.05016352227260602\n",
      "Testing error: 1.1585046809316413\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 21\n",
      "Training error: 0.05013685665386968\n",
      "Testing error: 1.158318651965933\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 22\n",
      "Training error: 0.050114908721996296\n",
      "Testing error: 1.1581603759128256\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 23\n",
      "Training error: 0.05009683180111318\n",
      "Testing error: 1.1580230962224731\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 24\n",
      "Training error: 0.05008194516962157\n",
      "Testing error: 1.15790194047775\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 25\n",
      "Training error: 0.05006969745281697\n",
      "Testing error: 1.1577933733126253\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 26\n",
      "Training error: 0.05005963915664146\n",
      "Testing error: 1.157694812678383\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 27\n",
      "Training error: 0.050051401781613165\n",
      "Testing error: 1.1576043593735676\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 28\n",
      "Training error: 0.050044681749660216\n",
      "Testing error: 1.1575206055140737\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 29\n",
      "Training error: 0.05003922790161865\n",
      "Testing error: 1.1574424982865683\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 30\n",
      "Training error: 0.050034831677718314\n",
      "Testing error: 1.1573692425965287\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 31\n",
      "Training error: 0.05003131933743032\n",
      "Testing error: 1.1573002312036114\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 32\n",
      "Training error: 0.05002854574588695\n",
      "Testing error: 1.157234994369211\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 33\n",
      "Training error: 0.050026389375479687\n",
      "Testing error: 1.1571731634166647\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 34\n",
      "Training error: 0.05002474825864864\n",
      "Testing error: 1.1571144442559809\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 35\n",
      "Training error: 0.0500235366915504\n",
      "Testing error: 1.1570585980776138\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 36\n",
      "Training error: 0.05002268253514983\n",
      "Testing error: 1.1570054272272137\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 37\n",
      "Training error: 0.05002212499511771\n",
      "Testing error: 1.156954764841316\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 38\n",
      "Training error: 0.05002181278802059\n",
      "Testing error: 1.156906467224794\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 39\n",
      "Training error: 0.050021702621059864\n",
      "Testing error: 1.1568604082351428\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 40\n",
      "Training error: 0.05002175792768394\n",
      "Testing error: 1.15681647514109\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 41\n",
      "Training error: 0.05002194781302375\n",
      "Testing error: 1.1567745655676105\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 42\n",
      "Training error: 0.050022246172106315\n",
      "Testing error: 1.1567345852435444\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 43\n",
      "Training error: 0.05002263095087585\n",
      "Testing error: 1.1566964463431033\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 44\n",
      "Training error: 0.050023083525633776\n",
      "Testing error: 1.1566600662671414\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.05002358818094862\n",
      "Testing error: 1.1566253667500017\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 46\n",
      "Training error: 0.050024131669658446\n",
      "Testing error: 1.1565922732069258\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 47\n",
      "Training error: 0.050024702841462085\n",
      "Testing error: 1.156560714258855\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 48\n",
      "Training error: 0.05002529232893524\n",
      "Testing error: 1.1565306213873117\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 49\n",
      "Training error: 0.05002589228171316\n",
      "Testing error: 1.1565019286841964\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Iteration: 50\n",
      "Training error: 0.05002649614114599\n",
      "Testing error: 1.1564745726702201\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05002649614114599, 1.1564745726702201)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 80\n",
    "reg = 5.0\n",
    "U_init = np.apply_along_axis(lambda x: x/sum(x), 1, abs(np.random.randn(X_tr.shape[0],k)))\n",
    "V_init = np.apply_along_axis(lambda x: x/sum(x), 1, abs(np.random.randn(k,X_tr.shape[1])))\n",
    "train(X_tr, X_te, U_init, V_init, k, niters = 50, reg = reg, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
