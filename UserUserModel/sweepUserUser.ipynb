{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep Weighted UserUser Params\n",
    "In this notebook, we sweep through the params w1 and w2 for our weighted user user model.\n",
    "1. w1 = 0.0 - 5.0 (using step of 0.1)\n",
    "2. w2 = 0.0 - 5.0 (using step of 0.1)\n",
    "\n",
    "Output: a json file that contains key (w1, w2) mapped to a value which is the test data MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import gc\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 15,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = sp.load_npz(\"rating_matrix_shrunk.npz\")\n",
    "isRead = sp.load_npz(\"isRead_matrix_shrunk.npz\")\n",
    "shelved = sp.load_npz(\"shelved_matrix_shrunk.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change params here\n",
    "w1_range = np.arange(4.7, 5.1, 0.1)\n",
    "w2_range = np.arange(0, 5.1, 0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function helps us linearly combine the three matrix into the weighted matrixwe will use to feed into the weighted user user model. For exactly how we sum up the weights and matrices, pleaes see our final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to string the three matricies together into one with differerent weights on each number\n",
    "def threeMatricesWeight (w1, w2, shelved, isRead, rating):\n",
    "    '''\n",
    "    w1 : weight to apply on shelved\n",
    "    w2 : weight to apply on intermediate\n",
    "    '''\n",
    "    if (not isinstance(isRead, np.ndarray)):\n",
    "        isRead = np.asarray(isRead.todense())\n",
    "        shelved = np.asarray(shelved.todense())\n",
    "        rating = np.asarray(rating.todense())\n",
    "    \n",
    "    isRead_zero_indices = (isRead == 0)\n",
    "    \n",
    "    intermediate = shelved * w1 * isRead_zero_indices\n",
    "    \n",
    "    intermediate = isRead * w2 + intermediate\n",
    "    \n",
    "    rating_zero_indices = (rating == 0)\n",
    "    \n",
    "    return intermediate * rating_zero_indices + rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to calculate the similarity between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pearson(X, nnz_indices, user_means, min_common_items=5):\n",
    "    X_norm = (X - user_means[:,None]) * nnz_indices\n",
    "    X_col_norm = (X_norm**2) @ (X_norm != 0).T\n",
    "    common_items = nnz_indices.astype(float) @ nnz_indices.T\n",
    "    return (X_norm @ X_norm.T) / (np.sqrt(X_col_norm*X_col_norm.T)+1e-12) * (common_items >= min_common_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to predict a single user's ratings of all the books in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_user_user(X, nnz_indices, W, user_means, diff, i, j):\n",
    "    \"\"\" Return prediction of X_(ij). \"\"\"\n",
    "    return user_means[i] + (\n",
    "        np.sum(diff[:,j] * nnz_indices[:,j] * W[i,:]) / \n",
    "        (np.sum(nnz_indices[:,j] * np.abs(W[i,:])) + 1e-12)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple MSE function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(prediction_array, original_array):\n",
    "    \"\"\"\n",
    "        prediction array: np array\n",
    "        original_array: np array\n",
    "    \"\"\"\n",
    "    return np.sum((prediction_array - original_array)** 2) / len(nonzero_ratings_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we used a seed in our random. This is to ensure that in every model we are train test splitting the same way on the matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: Mean of empty slice.\n",
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#Set up train data\n",
    "dense_rating_matrix = np.asarray(rating.todense())\n",
    "X_tr = dense_rating_matrix.copy()\n",
    "X_tr = X_tr.flatten()\n",
    "\n",
    "nonzero_pairs = np.nonzero(X_tr)[0]\n",
    "num_non_zero_pairs = len(nonzero_pairs)\n",
    "\n",
    "total_num_pairs = X_tr.shape[0]\n",
    "num_testing_pairs = int(0.1 * num_non_zero_pairs)\n",
    "\n",
    "# seeds the random generator\n",
    "np.random.seed(0)\n",
    "\n",
    "# indices of 1d array X_tr\n",
    "testing_pair_indices = np.random.choice(nonzero_pairs, num_testing_pairs, replace=False)\n",
    "training_pair_indices = list(set(np.arange(total_num_pairs)) - set(testing_pair_indices))\n",
    "\n",
    "#set up test data\n",
    "X_te = X_tr.copy()\n",
    "\n",
    "# sets testing pairs in training set to be 0\n",
    "X_tr[testing_pair_indices] = 0\n",
    "\n",
    "# sets training pairs in testing set to be 0\n",
    "X_te[training_pair_indices] = 0\n",
    "\n",
    "# takes X_tr and X_te back to shape of dense_rating_matrix\n",
    "X_tr = X_tr.reshape((dense_rating_matrix.shape[0], dense_rating_matrix.shape[1]))\n",
    "X_te = X_te.reshape((dense_rating_matrix.shape[0], dense_rating_matrix.shape[1]))\n",
    "\n",
    "#find where indices are nonzero\n",
    "nonzero_rating_list_te = sp.find(X_te)\n",
    "users_te, books_te, nonzero_ratings_te = nonzero_rating_list_te\n",
    "nnz_indices_tr = (X_tr != 0)\n",
    "nnz_indices_te = (X_te != 0)\n",
    "\n",
    "#find user_means\n",
    "user_means = np.array([X_tr[i,nnz_indices_tr[i,:]].mean() for i in range(X_tr.shape[0])])\n",
    "user_means = np.nan_to_num(user_means, 0)\n",
    "diff_tr = X_tr - user_means[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweep Through w1 and w2\n",
    "Here we start sweeping through the w1 and w2 ranges that we specified at the top of the notebook. We save the test MSE results into a json file everytime w2 finishes its loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(w1, w2)    error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice.\n",
      "  del sys.path[0]\n",
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.7, 0.0)  0.9888967951673145\n",
      "(4.7, 0.1)  0.993100240989649\n",
      "(4.7, 0.2)  0.9929983734457559\n",
      "(4.7, 0.30000000000000004)  0.9928544633629018\n",
      "(4.7, 0.4)  0.9927440537217554\n",
      "(4.7, 0.5)  0.9926372309072099\n",
      "(4.7, 0.6000000000000001)  0.9925004360360011\n",
      "(4.7, 0.7000000000000001)  0.9924342834842992\n",
      "(4.7, 0.8)  0.9922733381336448\n",
      "(4.7, 0.9)  0.9922127319708536\n",
      "(4.7, 1.0)  0.9920852414854237\n",
      "(4.7, 1.1)  0.9919441965067892\n",
      "(4.7, 1.2000000000000002)  0.9920498740629606\n",
      "(4.7, 1.3)  0.9919704091075656\n",
      "(4.7, 1.4000000000000001)  0.9918455451231729\n",
      "(4.7, 1.5)  0.9917451411813873\n",
      "(4.7, 1.6)  0.9916914967205419\n",
      "(4.7, 1.7000000000000002)  0.9915261832408542\n",
      "(4.7, 1.8)  0.9914758882619864\n",
      "(4.7, 1.9000000000000001)  0.9913768099807765\n",
      "(4.7, 2.0)  0.9913103610195539\n",
      "(4.7, 2.1)  0.9911777537231365\n",
      "(4.7, 2.2)  0.9911296880127536\n",
      "(4.7, 2.3000000000000003)  0.9910418063094953\n",
      "(4.7, 2.4000000000000004)  0.9911087120493296\n",
      "(4.7, 2.5)  0.9910165811913014\n",
      "(4.7, 2.6)  0.9910189620126777\n",
      "(4.7, 2.7)  0.9909379117286597\n",
      "(4.7, 2.8000000000000003)  0.9907775479125971\n",
      "(4.7, 2.9000000000000004)  0.9908374931996246\n",
      "(4.7, 3.0)  0.9907227153330049\n",
      "(4.7, 3.1)  0.9906295396236525\n",
      "(4.7, 3.2)  0.990559851847976\n",
      "(4.7, 3.3000000000000003)  0.9905446994836893\n",
      "(4.7, 3.4000000000000004)  0.9905528767016561\n",
      "(4.7, 3.5)  0.9905417172645996\n",
      "(4.7, 3.6)  0.9904784833903459\n",
      "(4.7, 3.7)  0.9904853725617052\n",
      "(4.7, 3.8000000000000003)  0.9905165268997851\n",
      "(4.7, 3.9000000000000004)  0.9904765848732274\n",
      "(4.7, 4.0)  0.9904414183806394\n",
      "(4.7, 4.1000000000000005)  0.9904707301532238\n",
      "(4.7, 4.2)  0.9904892872641651\n",
      "(4.7, 4.3)  0.9903865563698533\n",
      "(4.7, 4.4)  0.9902591966080754\n",
      "(4.7, 4.5)  0.9901034460756355\n",
      "(4.7, 4.6000000000000005)  0.9900076628166283\n",
      "(4.7, 4.7)  0.9899685224012568\n",
      "(4.7, 4.800000000000001)  0.9897378446031784\n",
      "(4.7, 4.9)  0.9900742728550849\n",
      "(4.7, 5.0)  0.9895978687957496\n",
      "w1 = 4.7 saved\n",
      "\n",
      "(4.8, 0.0)  0.9908138711537223\n",
      "(4.8, 0.1)  0.9954230276063669\n",
      "(4.8, 0.2)  0.9953178192758037\n",
      "(4.8, 0.30000000000000004)  0.9952262614523738\n",
      "(4.8, 0.4)  0.9950863387866715\n",
      "(4.8, 0.5)  0.9949857032213513\n",
      "(4.8, 0.6000000000000001)  0.9949141443280825\n",
      "(4.8, 0.7000000000000001)  0.9947728306977135\n",
      "(4.8, 0.8)  0.9946247550647478\n",
      "(4.8, 0.9)  0.9945538758630105\n",
      "(4.8, 1.0)  0.9944687951400153\n",
      "(4.8, 1.1)  0.9945267691909349\n",
      "(4.8, 1.2000000000000002)  0.9944459098896199\n",
      "(4.8, 1.3)  0.9943218945197331\n",
      "(4.8, 1.4000000000000001)  0.9942796623237183\n",
      "(4.8, 1.5)  0.9941266699547373\n",
      "(4.8, 1.6)  0.9940357130122928\n",
      "(4.8, 1.7000000000000002)  0.9939426528188677\n",
      "(4.8, 1.8)  0.993838640269367\n",
      "(4.8, 1.9000000000000001)  0.9937640584526741\n",
      "(4.8, 2.0)  0.9936745994391292\n",
      "(4.8, 2.1)  0.9936472401117643\n",
      "(4.8, 2.2)  0.9935272789407292\n",
      "(4.8, 2.3000000000000003)  0.993579091595258\n",
      "(4.8, 2.4000000000000004)  0.9935164556423279\n",
      "(4.8, 2.5)  0.9934310842205921\n",
      "(4.8, 2.6)  0.99337903390204\n",
      "(4.8, 2.7)  0.9933054737534497\n",
      "(4.8, 2.8000000000000003)  0.993244866811518\n",
      "(4.8, 2.9000000000000004)  0.9932110967929891\n",
      "(4.8, 3.0)  0.9930865970387387\n",
      "(4.8, 3.1)  0.9929434221761587\n",
      "(4.8, 3.2)  0.9929210334253387\n",
      "(4.8, 3.3000000000000003)  0.9928566186606758\n",
      "(4.8, 3.4000000000000004)  0.9928398130838969\n",
      "(4.8, 3.5)  0.9928025524087487\n",
      "(4.8, 3.6)  0.9927783389451913\n",
      "(4.8, 3.7)  0.9927376197675832\n",
      "(4.8, 3.8000000000000003)  0.9927008664644958\n",
      "(4.8, 3.9000000000000004)  0.992670925314495\n",
      "(4.8, 4.0)  0.9926206112779227\n",
      "(4.8, 4.1000000000000005)  0.9926350006695227\n",
      "(4.8, 4.2)  0.9926238124319633\n",
      "(4.8, 4.3)  0.9924568853014593\n",
      "(4.8, 4.4)  0.9923668869514869\n",
      "(4.8, 4.5)  0.9924771686234798\n",
      "(4.8, 4.6000000000000005)  0.9923951582939882\n",
      "(4.8, 4.7)  0.9922726942372956\n",
      "(4.8, 4.800000000000001)  0.9912132816368908\n",
      "(4.8, 4.9)  0.9918059438755346\n",
      "(4.8, 5.0)  0.9915971157228516\n",
      "w1 = 4.8 saved\n",
      "\n",
      "(4.8999999999999995, 0.0)  0.9932063675880299\n",
      "(4.8999999999999995, 0.1)  0.9972750223896103\n",
      "(4.8999999999999995, 0.2)  0.9971764630565325\n",
      "(4.8999999999999995, 0.30000000000000004)  0.9971017722984522\n",
      "(4.8999999999999995, 0.4)  0.9969949670420571\n",
      "(4.8999999999999995, 0.5)  0.9968610010370168\n",
      "(4.8999999999999995, 0.6000000000000001)  0.9967536273631754\n",
      "(4.8999999999999995, 0.7000000000000001)  0.9966480271989667\n",
      "(4.8999999999999995, 0.8)  0.996532290734414\n",
      "(4.8999999999999995, 0.9)  0.9964549123748137\n",
      "(4.8999999999999995, 1.0)  0.9963554963650547\n",
      "(4.8999999999999995, 1.1)  0.9964497298404648\n",
      "(4.8999999999999995, 1.2000000000000002)  0.9963317616907684\n",
      "(4.8999999999999995, 1.3)  0.9962494261732231\n",
      "(4.8999999999999995, 1.4000000000000001)  0.9961505178910991\n",
      "(4.8999999999999995, 1.5)  0.9960641153431078\n",
      "(4.8999999999999995, 1.6)  0.9959942785958905\n",
      "(4.8999999999999995, 1.7000000000000002)  0.9959187760790706\n",
      "(4.8999999999999995, 1.8)  0.9958183974144467\n",
      "(4.8999999999999995, 1.9000000000000001)  0.9957420663187723\n",
      "(4.8999999999999995, 2.0)  0.995686750194713\n",
      "(4.8999999999999995, 2.1)  0.9956097681430054\n",
      "(4.8999999999999995, 2.2)  0.9956940638741755\n",
      "(4.8999999999999995, 2.3000000000000003)  0.9956298379712434\n",
      "(4.8999999999999995, 2.4000000000000004)  0.9955643167955907\n",
      "(4.8999999999999995, 2.5)  0.9955147016443011\n",
      "(4.8999999999999995, 2.6)  0.9954591554009914\n",
      "(4.8999999999999995, 2.7)  0.9954074038368487\n",
      "(4.8999999999999995, 2.8000000000000003)  0.9953512715595553\n",
      "(4.8999999999999995, 2.9000000000000004)  0.9953051388074143\n",
      "(4.8999999999999995, 3.0)  0.9951967320322493\n",
      "(4.8999999999999995, 3.1)  0.9950713000122706\n",
      "(4.8999999999999995, 3.2)  0.9949994205053977\n",
      "(4.8999999999999995, 3.3000000000000003)  0.9950561424450557\n",
      "(4.8999999999999995, 3.4000000000000004)  0.9950299078892378\n",
      "(4.8999999999999995, 3.5)  0.9950098079699753\n",
      "(4.8999999999999995, 3.6)  0.9949911942219727\n",
      "(4.8999999999999995, 3.7)  0.9949337526660714\n",
      "(4.8999999999999995, 3.8000000000000003)  0.9949183626307846\n",
      "(4.8999999999999995, 3.9000000000000004)  0.9948624793250553\n",
      "(4.8999999999999995, 4.0)  0.9948165387969015\n",
      "(4.8999999999999995, 4.1000000000000005)  0.9948164015272748\n",
      "(4.8999999999999995, 4.2)  0.9947424496983306\n",
      "(4.8999999999999995, 4.3)  0.9946916148922571\n",
      "(4.8999999999999995, 4.4)  0.9946170966393124\n",
      "(4.8999999999999995, 4.5)  0.9945242824716238\n",
      "(4.8999999999999995, 4.6000000000000005)  0.994496810991184\n",
      "(4.8999999999999995, 4.7)  0.9943339915172582\n",
      "(4.8999999999999995, 4.800000000000001)  0.9944462011223222\n",
      "(4.8999999999999995, 4.9)  0.9932009737851147\n",
      "(4.8999999999999995, 5.0)  0.9935956653626487\n",
      "w1 = 4.8999999999999995 saved\n",
      "\n",
      "(4.999999999999999, 0.0)  0.9978639304424585\n",
      "(4.999999999999999, 0.1)  0.9991884577447258\n",
      "(4.999999999999999, 0.2)  0.9990856715023824\n",
      "(4.999999999999999, 0.30000000000000004)  0.9989982454180394\n",
      "(4.999999999999999, 0.4)  0.9989152684627782\n",
      "(4.999999999999999, 0.5)  0.9988303510471951\n",
      "(4.999999999999999, 0.6000000000000001)  0.9987429560047028\n",
      "(4.999999999999999, 0.7000000000000001)  0.9986615815751742\n",
      "(4.999999999999999, 0.8)  0.9985741650294658\n",
      "(4.999999999999999, 0.9)  0.9985062780503496\n",
      "(4.999999999999999, 1.0)  0.9986927940605427\n",
      "(4.999999999999999, 1.1)  0.9985388138495804\n",
      "(4.999999999999999, 1.2000000000000002)  0.9984730166042384\n",
      "(4.999999999999999, 1.3)  0.9984023261821576\n",
      "(4.999999999999999, 1.4000000000000001)  0.9983363991105304\n",
      "(4.999999999999999, 1.5)  0.9982930651053865\n",
      "(4.999999999999999, 1.6)  0.9982202095497434\n",
      "(4.999999999999999, 1.7000000000000002)  0.9981709666165535\n",
      "(4.999999999999999, 1.8)  0.9981178994577835\n",
      "(4.999999999999999, 1.9000000000000001)  0.9980649612543844\n",
      "(4.999999999999999, 2.0)  0.9981381768044755\n",
      "(4.999999999999999, 2.1)  0.9982422832181512\n",
      "(4.999999999999999, 2.2)  0.9982016773573213\n",
      "(4.999999999999999, 2.3000000000000003)  0.9981626959336474\n",
      "(4.999999999999999, 2.4000000000000004)  0.9981303563146416\n",
      "(4.999999999999999, 2.5)  0.9981091876257668\n",
      "(4.999999999999999, 2.6)  0.9980616922055415\n",
      "(4.999999999999999, 2.7)  0.9980370060618563\n",
      "(4.999999999999999, 2.8000000000000003)  0.9980182544474101\n",
      "(4.999999999999999, 2.9000000000000004)  0.9980101526744377\n",
      "(4.999999999999999, 3.0)  0.9979810924134478\n",
      "(4.999999999999999, 3.1)  0.9978372780386601\n",
      "(4.999999999999999, 3.2)  0.9978609213592564\n",
      "(4.999999999999999, 3.3000000000000003)  0.9979487888663923\n",
      "(4.999999999999999, 3.4000000000000004)  0.9979877833186013\n",
      "(4.999999999999999, 3.5)  0.9980237054952832\n",
      "(4.999999999999999, 3.6)  0.9980526510622655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.999999999999999, 3.7)  0.9980838921142946\n",
      "(4.999999999999999, 3.8000000000000003)  0.9981731357267258\n",
      "(4.999999999999999, 3.9000000000000004)  0.9981748365274856\n",
      "(4.999999999999999, 4.0)  0.9983290191798014\n",
      "(4.999999999999999, 4.1000000000000005)  0.9985190739354101\n",
      "(4.999999999999999, 4.2)  0.9984764517144764\n",
      "(4.999999999999999, 4.3)  0.9984642389418885\n",
      "(4.999999999999999, 4.4)  0.9984489194753521\n",
      "(4.999999999999999, 4.5)  0.9984434488820503\n",
      "(4.999999999999999, 4.6000000000000005)  0.998341918676403\n",
      "(4.999999999999999, 4.7)  0.9983072509852264\n",
      "(4.999999999999999, 4.800000000000001)  0.9983165672272336\n",
      "(4.999999999999999, 4.9)  0.9984017214724886\n",
      "(4.999999999999999, 5.0)  0.9971025535420045\n",
      "w1 = 4.999999999999999 saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_dict = {}\n",
    "print (\"(w1, w2)\" + \"    \" + \"error\")\n",
    "for w1 in w1_range:\n",
    "    last_w2 = w2_range[-1]\n",
    "    for w2 in w2_range:\n",
    "        #Create combined matrix\n",
    "        combined_rating_matrix = threeMatricesWeight(w1, w2, shelved, isRead, rating)\n",
    "        combined_rating_matrix = combined_rating_matrix.flatten()\n",
    "        combined_rating_matrix[testing_pair_indices] = 0\n",
    "        combined_rating_matrix = combined_rating_matrix.reshape((dense_rating_matrix.shape[0], dense_rating_matrix.shape[1]))\n",
    "\n",
    "        nnz_indices_combined = (combined_rating_matrix != 0)\n",
    "        user_means_combined = np.array([combined_rating_matrix[i,nnz_indices_combined[i,:]].mean() for i in range(combined_rating_matrix.shape[0])])\n",
    "        user_means_combined = np.nan_to_num(user_means_combined, 0)\n",
    "\n",
    "        W_pearson_combined = all_pearson(combined_rating_matrix, nnz_indices_combined, user_means_combined)\n",
    "        predictions_te_combined = []\n",
    "        for index in range(len(users_te)):\n",
    "            user = users_te[index]\n",
    "            book = books_te[index]\n",
    "            predictions_te_combined.append(predict_single_user_user(X_tr, nnz_indices_tr, W_pearson_combined,\n",
    "                                                           user_means, diff_tr, user, book))\n",
    "        #get the error \n",
    "        param_dict[str((w1, w2))] = error(np.asarray(predictions_te_combined), nonzero_ratings_te)\n",
    "        print (str((w1, w2)) + \"  \" + str(param_dict[str((w1, w2))]))        \n",
    "        \n",
    "        #save the file when w2 finishes looping\n",
    "        if w2 == last_w2:\n",
    "            with open(\"user_user_sweep7\" + \".json\", \"w+\") as f:\n",
    "                json.dump(param_dict, f)\n",
    "                print (\"w1 = \" + str((w1)) + \" saved\")\n",
    "                print (\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unweighted Rating Matrix\n",
    "This is the benchmark model that our weighted user user model wants to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "1000 done\n",
      "2000 done\n",
      "3000 done\n",
      "4000 done\n",
      "5000 done\n",
      "6000 done\n",
      "7000 done\n",
      "8000 done\n",
      "9000 done\n",
      "10000 done\n",
      "11000 done\n",
      "12000 done\n",
      "13000 done\n",
      "14000 done\n",
      "15000 done\n",
      "16000 done\n"
     ]
    }
   ],
   "source": [
    "W_pearson = all_pearson(X_tr, nnz_indices_tr, user_means)\n",
    "predictions_te = []\n",
    "\n",
    "for index in range(len(users_te)):\n",
    "    user = users_te[index]\n",
    "    book = books_te[index]\n",
    "    predictions_te.append(predict_single_user_user(X_tr, nnz_indices_tr, W_pearson,\n",
    "                                                   user_means, diff_tr, user, book))\n",
    "    if (index % 1000 == 0):\n",
    "        print (str(index) + \" done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756388191656609"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((np.asarray(predictions_te) - nonzero_ratings_te) ** 2) / len(nonzero_ratings_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
